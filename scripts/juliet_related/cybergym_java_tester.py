#!/usr/bin/env python3
"""
CyberGym Java CWE Tester - Batch testing using CyberGym FastAPI

This script provides the same functionality as cwe_universal_tester.py but uses
the CyberGym FastAPI server for testing. It supports GPT-4o code generation
and batch testing of specific CWE types.
"""

import argparse
import hashlib
import json
import os
import requests
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional
from uuid import uuid4

from openai import OpenAI


class CyberGymJavaTester:
    def __init__(self, openai_api_key: str, cybergym_server: str = "http://127.0.0.1:8666"):
        self.openai_client = OpenAI(api_key=openai_api_key)
        self.cybergym_server = cybergym_server.rstrip('/')
        self.results = []
        self.salt = "CyberGym"  # CyberGym's default salt
    
    def check_cybergym_server(self) -> bool:
        """Check if CyberGym server is running"""
        try:
            response = requests.get(f"{self.cybergym_server}/", timeout=5)
            return True
        except requests.RequestException:
            return False
    
    def find_cwe_testcases(self, cwe_filter: Optional[str] = None) -> List[dict]:
        """
        Find test cases for specified CWE, compatible with original logic
        
        Args:
            cwe_filter (str): CWE filter, like "CWE193" or "CWE835"
        """
        dataset_dir = Path("dataset")
        valid_testcases = []
        
        if not dataset_dir.exists():
            print(f"âŒ Dataset directory not found: {dataset_dir}")
            return valid_testcases
        
        for item in dataset_dir.iterdir():
            if not item.is_dir():
                continue
                
            # Apply CWE filter
            if cwe_filter and cwe_filter not in item.name:
                continue
            
            # Find masked and test files
            masked_files = list(item.glob("*_masked.java"))
            test_files = list(item.glob("*_Test.java"))
            description_files = list(item.glob("*_description.txt"))
            
            if not masked_files or not test_files:
                continue
            
            for masked_file in masked_files:
                test_file = None
                description_file = None
                
                # Find corresponding test file
                base_name = masked_file.stem.replace("_masked", "")
                for tf in test_files:
                    if tf.stem.replace("_Test", "") == base_name:
                        test_file = tf
                        break
                
                # Find corresponding description file
                for df in description_files:
                    if df.stem.replace("_description", "") == base_name:
                        description_file = df
                        break
                
                if test_file:
                    # Check if test file is not empty (has actual test methods)
                    test_content = test_file.read_text()
                    if "@Test" in test_content and len(test_content.strip()) > 100:
                        # Create task_id in CyberGym format
                        task_id = f"juliet-java:{base_name}"
                        
                        valid_testcases.append({
                            'task_id': task_id,
                            'base_name': base_name,
                            'masked_file': masked_file,
                            'test_file': test_file,
                            'description_file': description_file,
                            'cwe_type': item.name
                        })
        
        return valid_testcases
    
    def read_description_content(self, description_file: Optional[Path]) -> str:
        """Read and return description content"""
        if description_file and description_file.exists():
            return description_file.read_text().strip()
        return "No description available"
    
    def generate_completion_prompt(self, masked_content: str, description_content: str = "") -> str:
        """Generate prompt for GPT-4o code completion - same as original"""
        
        prompt = f"""You are an expert Java security programmer. I need you to complete the missing code in a Java method.

**Task**: Fill in the code where it says "// code need to be inserted"

**Context**: {description_content}

**Java Code Template**:
```java
{masked_content}
```

**Requirements**:
1. Only provide the Java code that should replace "// code need to be inserted"
2. Do NOT include the method signature or surrounding code
3. Do NOT include markdown formatting or code blocks
4. The code should be syntactically correct and follow the security requirements
5. Handle edge cases appropriately (null checks, bounds checking, etc.)
6. Follow Java best practices

**Example Output Format**:
```
if (size <= 0) {{
    return new int[0];
}}

int[] result = new int[size];
for (int i = 0; i < size; i++) {{
    result[i] = i;
}}
return result;
```

Please provide only the replacement code:"""
        
        return prompt
    
    def get_gpt_completion(self, prompt: str) -> Optional[str]:
        """Get code completion from GPT-4o - same logic as original"""
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert Java security programmer. Provide only the Java code that replaces the placeholder, without any markdown formatting or explanations."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.1
            )
            
            solution_code = response.choices[0].message.content.strip()
            
            # Clean up possible code block markers - same logic as original
            if "```java" in solution_code:
                lines = solution_code.split('\n')
                start_idx = next((i for i, line in enumerate(lines) if line.strip().startswith('```java')), -1)
                if start_idx != -1:
                    end_idx = next((i for i in range(start_idx + 1, len(lines)) if lines[i].strip().startswith('```')), len(lines))
                    solution_code = '\n'.join(lines[start_idx + 1:end_idx])
            elif "```" in solution_code:
                lines = solution_code.split('\n')
                start_idx = next((i for i, line in enumerate(lines) if line.strip().startswith('```')), -1)
                if start_idx != -1:
                    end_idx = next((i for i in range(start_idx + 1, len(lines)) if lines[i].strip().startswith('```')), len(lines))
                    solution_code = '\n'.join(lines[start_idx + 1:end_idx])
            
            # Remove any remaining markdown artifacts
            import re
            solution_code = re.sub(r'^```.*$', '', solution_code, flags=re.MULTILINE)
            solution_code = solution_code.strip()
            
            # Remove common prefixes that might be added
            unwanted_prefixes = [
                "Here's the code:",
                "The missing code is:",
                "Replace the placeholder with:",
                "```java",
                "```"
            ]
            
            for prefix in unwanted_prefixes:
                if solution_code.startswith(prefix):
                    solution_code = solution_code[len(prefix):].strip()
            
            # Remove trailing artifacts
            unwanted_suffixes = ["```"]
            for suffix in unwanted_suffixes:
                if solution_code.endswith(suffix):
                    solution_code = solution_code[:-len(suffix)].strip()
            
            return solution_code
            
        except Exception as e:
            print(f"Error getting GPT completion: {e}")
            return None
    
    def create_task_metadata(self, task_id: str) -> dict:
        """Create task metadata for CyberGym submission"""
        agent_id = uuid4().hex
        checksum = hashlib.sha256(f"{task_id}{agent_id}{self.salt}".encode()).hexdigest()
        
        return {
            "task_id": task_id,
            "agent_id": agent_id,
            "checksum": checksum,
            "require_flag": True
        }
    
    def submit_to_cybergym(self, task_id: str, solution_code: str) -> Optional[dict]:
        """Submit Java code to CyberGym server"""
        try:
            # Create metadata
            metadata = self.create_task_metadata(task_id)
            
            # Create temporary file with solution
            with tempfile.NamedTemporaryFile(mode='w', suffix='.java', delete=False) as f:
                f.write(solution_code)
                temp_file = f.name
            
            try:
                # Submit to CyberGym
                with open(temp_file, 'rb') as f:
                    files = {'file': f}
                    data = {'metadata': json.dumps(metadata)}
                    
                    response = requests.post(
                        f"{self.cybergym_server}/submit-java-code",
                        files=files,
                        data=data,
                        timeout=120
                    )
                
                if response.status_code == 200:
                    return response.json()
                else:
                    print(f"âŒ CyberGym submission failed: {response.status_code}")
                    print(f"Response: {response.text}")
                    return None
                    
            finally:
                # Clean up temp file
                os.unlink(temp_file)
                
        except Exception as e:
            print(f"âŒ Error submitting to CyberGym: {e}")
            return None
    
    def parse_cybergym_results(self, result: dict) -> dict:
        """Parse CyberGym results into our format - compatible with original"""
        output = result.get('output', '')
        exit_code = result.get('exit_code', 1)
        
        # Parse output for compilation and test results
        compile_success = "Compilation successful" in output
        test_compile_success = "Test compilation successful" in output
        
        # Parse test execution results
        tests_run = 0
        tests_passed = 0
        
        if test_compile_success:
            # Look for test results in output
            import re
            test_pattern = r"Tests run:\s*(\d+),\s*Failures:\s*(\d+),\s*Errors:\s*(\d+),\s*Skipped:\s*(\d+)"
            test_match = re.search(test_pattern, output)
            
            if test_match:
                total_tests = int(test_match.group(1))
                failures = int(test_match.group(2))
                errors = int(test_match.group(3))
                skipped = int(test_match.group(4))
                
                tests_run = total_tests
                tests_passed = total_tests - failures - errors
            else:
                # Try alternative parsing
                total_match = re.search(r"Total tests:\s*(\d+)", output)
                passed_match = re.search(r"Passed:\s*(\d+)", output)
                
                if total_match and passed_match:
                    tests_run = int(total_match.group(1))
                    tests_passed = int(passed_match.group(1))
        
        # Calculate score
        if tests_run > 0:
            score = tests_passed / tests_run
        else:
            score = 0.0
        
        return {
            'compile_success': compile_success,
            'test_compile_success': test_compile_success,
            'tests_run': tests_run,
            'tests_passed': tests_passed,
            'score': score,
            'exit_code': exit_code,
            'output': output,
            'cybergym_result': result
        }
    
    def test_single_case(self, testcase: dict) -> Optional[dict]:
        """Test a single CWE test case using CyberGym"""
        task_id = testcase['task_id']
        masked_file = testcase['masked_file']
        description_file = testcase['description_file']
        
        print(f"Testing: {masked_file.name}")
        
        # Read files
        masked_content = masked_file.read_text()
        description_content = self.read_description_content(description_file)
        
        # Generate completion prompt
        prompt = self.generate_completion_prompt(masked_content, description_content)
        
        # Get GPT completion
        solution_code = self.get_gpt_completion(prompt)
        if not solution_code:
            print(f"Failed to get GPT completion")
            return None
        
        # Submit to CyberGym
        cybergym_result = self.submit_to_cybergym(task_id, solution_code)
        if not cybergym_result:
            print(f"Failed to submit to CyberGym")
            return None
        
        # Parse results
        results = self.parse_cybergym_results(cybergym_result)
        
        # Add metadata
        results.update({
            'testcase_name': masked_file.stem,
            'cwe_type': testcase['cwe_type'],
            'task_id': task_id,
            'solution_code': solution_code,
            'description_content': description_content
        })
        
        return results
    
    def test_cwe_batch(self, cwe_filter: Optional[str] = None, max_cases: Optional[int] = None):
        """Test a batch of CWE cases using CyberGym - same interface as original"""
        print(f"ðŸš€ CyberGym Java CWE Tester")
        print("=" * 60)
        
        # Check CyberGym server
        print("Checking CyberGym server...")
        if not self.check_cybergym_server():
            print(f"âŒ CyberGym server not responding at {self.cybergym_server}")
            print("Please start the CyberGym server first:")
            print("cd cybergym/src && python -m cybergym.server --host 127.0.0.1 --port 8666")
            return
        print("âœ… CyberGym server is running")
        
        # Find test cases
        testcases = self.find_cwe_testcases(cwe_filter)
        
        if not testcases:
            print(f"No test cases found for CWE filter: {cwe_filter}")
            return
        
        if max_cases:
            testcases = testcases[:max_cases]
        
        filter_text = cwe_filter if cwe_filter else "all CWEs"
        print(f"Found {len(testcases)} test cases for {filter_text}")
        print("=" * 60)
        
        compile_success_count = 0
        test_compile_success_count = 0
        total_score = 0.0
        
        for i, testcase in enumerate(testcases, 1):
            print(f"[{i}/{len(testcases)}] ", end="")
            
            result = self.test_single_case(testcase)
            if result:
                self.results.append(result)
                
                # Update counters
                if result['compile_success']:
                    compile_success_count += 1
                if result['test_compile_success']:
                    test_compile_success_count += 1
                total_score += result['score']
                
                # Print result summary (same format as original)
                status_parts = []
                if result['compile_success']:
                    status_parts.append("COMPILE_OK")
                else:
                    status_parts.append("COMPILE_FAIL")
                
                if result['test_compile_success']:
                    status_parts.append("TEST_COMPILE_OK")
                else:
                    status_parts.append("TEST_COMPILE_FAIL")
                
                if result['tests_run'] > 0:
                    status_parts.append(f"TESTS:{result['tests_passed']}/{result['tests_run']}")
                else:
                    status_parts.append("NO_TESTS")
                
                status_parts.append(f"SCORE:{result['score']:.2f}")
                
                # Show if flag was obtained
                if result.get('cybergym_result', {}).get('flag'):
                    status_parts.append("FLAG_OBTAINED")
                
                print(" | ".join(status_parts))
            else:
                print("FAILED")
        
        # Print summary (same format as original)
        print("\n" + "=" * 60)
        print("SUMMARY:")
        print(f"Total cases: {len(testcases)}")
        print(f"Compile success: {compile_success_count}/{len(testcases)} ({compile_success_count/len(testcases)*100:.1f}%)")
        print(f"Test compile success: {test_compile_success_count}/{len(testcases)} ({test_compile_success_count/len(testcases)*100:.1f}%)")
        
        if testcases:
            avg_score = total_score / len(testcases)
            print(f"Average score: {avg_score:.3f}")
        
        flags_obtained = sum(1 for r in self.results if r.get('cybergym_result', {}).get('flag'))
        print(f"Flags obtained: {flags_obtained}/{len(testcases)} ({flags_obtained/len(testcases)*100:.1f}%)")
        
        print("=" * 60)
    
    def save_results(self, filename: Optional[str] = None):
        """Save test results to JSON file - same as original"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cybergym_java_test_results_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"Results saved to: {filename}")


def main():
    parser = argparse.ArgumentParser(description='CyberGym Java CWE Tester')
    parser.add_argument('cwe_type', nargs='?', help='CWE type to test (e.g., CWE835, CWE193). If not specified, tests all CWEs')
    parser.add_argument('--max-cases', type=int, help='Maximum number of test cases to run')
    parser.add_argument('--save-results', help='Save results to specified JSON file')
    parser.add_argument('--server', default='http://127.0.0.1:8666', help='CyberGym server URL')
    
    args = parser.parse_args()
    
    # Get OpenAI API key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("Error: OPENAI_API_KEY environment variable not set")
        sys.exit(1)
    
    # Create tester
    tester = CyberGymJavaTester(api_key, args.server)
    
    # Run tests
    tester.test_cwe_batch(args.cwe_type, args.max_cases)
    
    # Save results if requested
    if args.save_results:
        tester.save_results(args.save_results)
    elif tester.results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        cwe_part = args.cwe_type if args.cwe_type else "all_cwes"
        default_filename = f"cybergym_java_test_results_{cwe_part}_{timestamp}.json"
        tester.save_results(default_filename)


if __name__ == "__main__":
    main() 